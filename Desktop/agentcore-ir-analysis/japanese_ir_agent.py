"""
æ—¥æœ¬èªå®Œå…¨å¯¾å¿œIRåˆ†æAgentCoreã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
ä¼æ¥­è³‡æ–™ãƒ»IRãƒ»æ±ºç®—æ›¸ãªã©ã®åŒ…æ‹¬çš„åˆ†æã‚·ã‚¹ãƒ†ãƒ 
"""

from bedrock_agentcore import BedrockAgentCoreApp
from typing import Dict, Any, List
import boto3
import json
import re

app = BedrockAgentCoreApp()

@app.entrypoint
def invoke(payload: dict) -> str:
    """
    æ—¥æœ¬èªå¯¾å¿œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    
    å¯¾å¿œã‚¯ã‚¨ãƒªä¾‹:
    - "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã®2024å¹´ç¬¬1å››åŠæœŸæ±ºç®—ã‚’åˆ†æã—ã¦ãã ã•ã„"
    - "ã‚½ãƒ‹ãƒ¼ã®è²¡å‹™æŒ‡æ¨™ã¨ROEã‚’è¨ˆç®—ã—ã¦"
    - "ä»»å¤©å ‚ã®å£²ä¸Šæ¨ç§»ã‚’éå»3å¹´åˆ†ã§æ¯”è¼ƒ"
    """
    
    query = payload.get('query', payload.get('prompt', 'åˆ†æã‚’ãŠæ‰‹ä¼ã„ã—ã¾ã™'))
    
    print(f"[ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] å—ä¿¡ã‚¯ã‚¨ãƒª: {query}")
    
    # 1. æ—¥æœ¬èªæ„å›³è§£æ
    analysis_result = analyze_japanese_query(query)
    print(f"[åˆ†æ] è§£æçµæœ: {analysis_result}")
    
    # 2. å¿…è¦ãªå‡¦ç†ã‚’å®Ÿè¡Œ
    results = []
    
    if analysis_result.get('needs_document_search'):
        search_result = search_japanese_documents(query, analysis_result)
        results.append(search_result)
    
    if analysis_result.get('needs_financial_calculation'):
        calc_result = calculate_financial_metrics(query, analysis_result)
        results.append(calc_result)
    
    if analysis_result.get('needs_trend_analysis'):
        trend_result = analyze_business_trends(query, analysis_result)
        results.append(trend_result)
    
    # 3. æ—¥æœ¬èªã§çµ±åˆå›ç­”ç”Ÿæˆ
    final_response = generate_japanese_response(query, results, analysis_result)
    
    return final_response

def analyze_japanese_query(query: str) -> Dict[str, Any]:
    """æ—¥æœ¬èªã‚¯ã‚¨ãƒªã®è©³ç´°åˆ†æ"""
    
    # ä¼æ¥­åæŠ½å‡º
    company_patterns = [
        r'(ãƒˆãƒ¨ã‚¿|TOYOTA|toyota)',
        r'(ã‚½ãƒ‹ãƒ¼|SONY|sony)', 
        r'(ä»»å¤©å ‚|Nintendo|nintendo)',
        r'(ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯|SoftBank|softbank)',
        r'(æ¥½å¤©|Rakuten|rakuten)',
        r'(ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯|Panasonic|panasonic)'
    ]
    
    detected_companies = []
    for pattern in company_patterns:
        if re.search(pattern, query, re.IGNORECASE):
            detected_companies.append(re.search(pattern, query, re.IGNORECASE).group(1))
    
    # åˆ†æã‚¿ã‚¤ãƒ—åˆ¤å®š
    intent_keywords = {
        'document_search': [
            'æ±ºç®—', 'è²¡å‹™', 'æ¥­ç¸¾', 'IR', 'è³‡æ–™', 'å ±å‘Šæ›¸', 'åˆ†æ',
            'æ±ºç®—æ›¸', 'æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸', 'å››åŠæœŸ', 'å¹´æ¬¡', 'ä¸­æœŸè¨ˆç”»'
        ],
        'financial_calculation': [
            'ROE', 'ROA', 'PER', 'PBR', 'åˆ©ç›Šç‡', 'æˆé•·ç‡', 
            'å£²ä¸Šé«˜', 'å–¶æ¥­åˆ©ç›Š', 'ç´”åˆ©ç›Š', 'ç·è³‡ç”£', 'è‡ªå·±è³‡æœ¬'
        ],
        'trend_analysis': [
            'æ¨ç§»', 'å¤‰åŒ–', 'æ¯”è¼ƒ', 'ãƒˆãƒ¬ãƒ³ãƒ‰', 'æˆé•·', 'æ¸›å°‘',
            'éå»', 'å°†æ¥', 'äºˆæ¸¬', 'è¦‹é€šã—', 'å‚¾å‘'
        ],
        'time_period': [
            '2024å¹´', '2023å¹´', '2022å¹´', 'ç¬¬1å››åŠæœŸ', 'ç¬¬2å››åŠæœŸ',
            'ç¬¬3å››åŠæœŸ', 'ç¬¬4å››åŠæœŸ', 'ä¸ŠåŠæœŸ', 'ä¸‹åŠæœŸ', 'å¹´åº¦'
        ]
    }
    
    detected_intents = {}
    for intent_type, keywords in intent_keywords.items():
        matches = [kw for kw in keywords if kw in query]
        detected_intents[intent_type] = matches
    
    return {
        'original_query': query,
        'detected_companies': detected_companies,
        'primary_company': detected_companies[0] if detected_companies else None,
        'needs_document_search': bool(detected_intents['document_search']),
        'needs_financial_calculation': bool(detected_intents['financial_calculation']),
        'needs_trend_analysis': bool(detected_intents['trend_analysis']),
        'time_period': detected_intents.get('time_period', []),
        'financial_metrics': detected_intents.get('financial_calculation', []),
        'analysis_focus': detected_intents
    }

def search_japanese_documents(query: str, analysis: Dict) -> Dict[str, Any]:
    """æ—¥æœ¬èªæ–‡æ›¸æ¤œç´¢ï¼ˆS3 + Titan Embedï¼‰"""
    
    try:
        # AWS Bedrock Runtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        bedrock_runtime = boto3.client("bedrock-runtime", region_name="us-east-1")
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–
        company = analysis.get('primary_company', 'ä¼æ¥­')
        search_query = f"{company} {' '.join(analysis.get('financial_metrics', []))} è²¡å‹™åˆ†æ"
        
        # Titan Embedã«ã‚ˆã‚‹åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        response = bedrock_runtime.invoke_model(
            body=json.dumps({"inputText": search_query}),
            modelId="amazon.titan-embed-text-v2:0",
            contentType="application/json",
            accept="application/json"
        )
        
        embedding_result = json.loads(response.get("body").read())
        query_embedding = embedding_result.get("embedding")
        
        if query_embedding:
            # å®Ÿéš›ã®ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼ˆç°¡ç•¥åŒ–ï¼‰
            return {
                "status": "success",
                "search_query": search_query,
                "company": company,
                "documents_found": 5,
                "top_matches": [
                    f"{company}_2024å¹´ç¬¬1å››åŠæœŸæ±ºç®—çŸ­ä¿¡.pdf",
                    f"{company}_2023å¹´åº¦æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸.pdf", 
                    f"{company}_ä¸­æœŸçµŒå–¶è¨ˆç”»2024-2026.pdf"
                ],
                "similarity_scores": [0.89, 0.82, 0.76],
                "key_findings": [
                    f"{company}ã®å£²ä¸Šé«˜ã¯å‰å¹´åŒæœŸæ¯”12.5%å¢—",
                    "å–¶æ¥­åˆ©ç›Šç‡ã¯8.2%ã§æ¥­ç•Œå¹³å‡ã‚’ä¸Šå›ã‚‹",
                    "è‡ªå·±è³‡æœ¬æ¯”ç‡ã¯65.4%ã§è²¡å‹™å¥å…¨æ€§è‰¯å¥½"
                ]
            }
        else:
            return {"status": "error", "message": "åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"}
            
    except Exception as e:
        return {"status": "error", "message": f"æ–‡æ›¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"}

def calculate_financial_metrics(query: str, analysis: Dict) -> Dict[str, Any]:
    """è²¡å‹™æŒ‡æ¨™è¨ˆç®—ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰"""
    
    company = analysis.get('primary_company', 'å¯¾è±¡ä¼æ¥­')
    metrics = analysis.get('financial_metrics', [])
    
    # ã‚µãƒ³ãƒ—ãƒ«è²¡å‹™ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯S3ç­‰ã‹ã‚‰å–å¾—ï¼‰
    sample_data = {
        'sales_revenue': 28500000,  # å£²ä¸Šé«˜ï¼ˆç™¾ä¸‡å††ï¼‰
        'operating_profit': 2280000,  # å–¶æ¥­åˆ©ç›Š
        'net_income': 1710000,  # å½“æœŸç´”åˆ©ç›Š  
        'total_assets': 45200000,  # ç·è³‡ç”£
        'shareholders_equity': 29500000,  # è‡ªå·±è³‡æœ¬
        'shares_outstanding': 1580000  # ç™ºè¡Œæ¸ˆæ ªå¼æ•°ï¼ˆåƒæ ªï¼‰
    }
    
    # è²¡å‹™æŒ‡æ¨™è¨ˆç®—
    calculated_metrics = {}
    
    if 'ROE' in str(metrics) or 'roe' in query.lower():
        roe = (sample_data['net_income'] / sample_data['shareholders_equity']) * 100
        calculated_metrics['ROE'] = f"{roe:.1f}%"
    
    if 'ROA' in str(metrics) or 'roa' in query.lower():
        roa = (sample_data['net_income'] / sample_data['total_assets']) * 100
        calculated_metrics['ROA'] = f"{roa:.1f}%"
    
    if 'åˆ©ç›Šç‡' in query or 'å–¶æ¥­åˆ©ç›Š' in query:
        margin = (sample_data['operating_profit'] / sample_data['sales_revenue']) * 100
        calculated_metrics['å–¶æ¥­åˆ©ç›Šç‡'] = f"{margin:.1f}%"
    
    return {
        "status": "success",
        "company": company,
        "period": "2024å¹´ç¬¬1å››åŠæœŸ",
        "calculated_metrics": calculated_metrics,
        "base_data": {
            "å£²ä¸Šé«˜": f"{sample_data['sales_revenue']:,}ç™¾ä¸‡å††",
            "å–¶æ¥­åˆ©ç›Š": f"{sample_data['operating_profit']:,}ç™¾ä¸‡å††", 
            "å½“æœŸç´”åˆ©ç›Š": f"{sample_data['net_income']:,}ç™¾ä¸‡å††",
            "ç·è³‡ç”£": f"{sample_data['total_assets']:,}ç™¾ä¸‡å††",
            "è‡ªå·±è³‡æœ¬": f"{sample_data['shareholders_equity']:,}ç™¾ä¸‡å††"
        }
    }

def analyze_business_trends(query: str, analysis: Dict) -> Dict[str, Any]:
    """äº‹æ¥­ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
    
    company = analysis.get('primary_company', 'å¯¾è±¡ä¼æ¥­')
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿
    trend_data = {
        "å£²ä¸Šé«˜æ¨ç§»": {
            "2022å¹´": "24,800ç™¾ä¸‡å††",
            "2023å¹´": "26,200ç™¾ä¸‡å††", 
            "2024å¹´Q1": "7,125ç™¾ä¸‡å††"
        },
        "æˆé•·ç‡": {
            "2023å¹´æˆé•·ç‡": "+5.6%",
            "2024å¹´äºˆæƒ³": "+8.8%"
        }
    }
    
    return {
        "status": "success",
        "company": company,
        "trend_analysis": trend_data,
        "insights": [
            f"{company}ã¯å®‰å®šã—ãŸæˆé•·è»Œé“ã‚’ç¶­æŒ",
            "å¸‚å ´ã‚·ã‚§ã‚¢æ‹¡å¤§ã«ã‚ˆã‚Šç«¶åˆå„ªä½æ€§ã‚’ç¢ºä¿",
            "ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©æŠ•è³‡ãŒåç›Šæ€§å‘ä¸Šã«å¯„ä¸"
        ]
    }

def generate_japanese_response(query: str, results: List[Dict], analysis: Dict) -> str:
    """æ—¥æœ¬èªçµ±åˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""
    
    company = analysis.get('primary_company', 'ã”æŒ‡å®šã®ä¼æ¥­')
    
    response_parts = [
        f"ğŸ¯ ã€{query}ã€ã®åˆ†æçµæœã‚’ãŠå ±å‘Šã„ãŸã—ã¾ã™\n",
        f"ğŸ“Š **{company} åŒ…æ‹¬åˆ†æãƒ¬ãƒãƒ¼ãƒˆ**",
        "=" * 50
    ]
    
    for result in results:
        if result.get("status") == "success":
            
            # æ–‡æ›¸æ¤œç´¢çµæœ
            if "documents_found" in result:
                response_parts.extend([
                    "\nğŸ“‹ **æ–‡æ›¸æ¤œç´¢çµæœ**",
                    f"æ¤œç´¢å¯¾è±¡: {result['company']}",
                    f"ç™ºè¦‹æ–‡æ›¸æ•°: {result['documents_found']}ä»¶",
                    "\nğŸ” **ä¸»è¦æ–‡æ›¸**:"
                ])
                
                for i, doc in enumerate(result['top_matches'], 1):
                    similarity = result['similarity_scores'][i-1]
                    response_parts.append(f"  {i}. {doc} (é–¢é€£åº¦: {similarity:.0%})")
                
                if result.get('key_findings'):
                    response_parts.extend([
                        "\nğŸ’¡ **ä¸»è¦ç™ºè¦‹äº‹é …**:"
                    ])
                    for finding in result['key_findings']:
                        response_parts.append(f"  â€¢ {finding}")
            
            # è²¡å‹™è¨ˆç®—çµæœ
            if "calculated_metrics" in result:
                response_parts.extend([
                    "\nğŸ“ˆ **è²¡å‹™æŒ‡æ¨™åˆ†æ**",
                    f"åˆ†ææœŸé–“: {result['period']}"
                ])
                
                if result['calculated_metrics']:
                    response_parts.append("\nğŸ§® **ç®—å‡ºæŒ‡æ¨™**:")
                    for metric, value in result['calculated_metrics'].items():
                        response_parts.append(f"  â€¢ {metric}: {value}")
                
                response_parts.extend([
                    "\nğŸ’° **åŸºç¤ãƒ‡ãƒ¼ã‚¿**:"
                ])
                for item, value in result['base_data'].items():
                    response_parts.append(f"  â€¢ {item}: {value}")
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æçµæœ
            if "trend_analysis" in result:
                response_parts.extend([
                    "\nğŸ“Š **ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ**"
                ])
                
                for trend_type, data in result['trend_analysis'].items():
                    response_parts.append(f"\nğŸ“ˆ **{trend_type}**:")
                    for period, value in data.items():
                        response_parts.append(f"  â€¢ {period}: {value}")
                
                if result.get('insights'):
                    response_parts.extend([
                        "\nğŸ”® **ã‚¤ãƒ³ã‚µã‚¤ãƒˆ**:"
                    ])
                    for insight in result['insights']:
                        response_parts.append(f"  â€¢ {insight}")
        
        else:
            response_parts.append(f"\nâš ï¸ **ã‚¨ãƒ©ãƒ¼**: {result.get('message', 'å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ')}")
    
    response_parts.extend([
        "\n" + "=" * 50,
        "ğŸ¤– **Amazon Bedrock AgentCore ã«ã‚ˆã‚‹åˆ†æå®Œäº†**",
        f"ğŸ“… å‡¦ç†æ—¥æ™‚: 2024å¹´9æœˆ11æ—¥",
        f"ğŸ” åˆ†æå¯¾è±¡: {company}",
        f"ğŸ“ å…ƒã‚¯ã‚¨ãƒª: {analysis['original_query']}"
    ])
    
    return "\n".join(response_parts)

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼ˆHTTPã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼‰
if __name__ == "__main__":
    import uvicorn
    
    print("=== æ—¥æœ¬èªIRåˆ†æAgentCoreèµ·å‹•ä¸­ ===")
    print("ã‚µãƒ¼ãƒãƒ¼: http://localhost:8080")
    print("ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: /invocations")
    print("å¯¾å¿œè¨€èª: æ—¥æœ¬èªå®Œå…¨å¯¾å¿œ")
    print("åˆ†æå¯¾è±¡: IRè³‡æ–™ã€æ±ºç®—æ›¸ã€ä¼æ¥­ãƒ¬ãƒãƒ¼ãƒˆç­‰")
    
    uvicorn.run(app, host="0.0.0.0", port=8080)